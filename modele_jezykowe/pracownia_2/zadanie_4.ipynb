{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77bfbe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Piotr Pijanowski\\Studia\\Semestr-5\\modele_jezykowe\\pracownia_2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b53b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"flax-community/papuGaPT2\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0ca80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 10\n",
    "TOPP = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf62d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otwieranie pliku z prefiskami\n",
    "\n",
    "with open('prefiksy.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    prefixes = f.read().split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e88da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_next_token_suggestions(prefix, top_k=20):\n",
    "    # Tokenizacja wejścia\n",
    "    input_ids = tokenizer(prefix, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    # Przepuszczenie przez model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "    # Logity ostatniego tokenu\n",
    "    logits = outputs.logits[0, -1]\n",
    "\n",
    "    # Softmax -> prawdopodobieństwa\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # Top-k najlepszych tokenów\n",
    "    top_probs, top_ids = torch.topk(probs, top_k)\n",
    "\n",
    "    print(f\"\\nPrefiks:\\n{prefix}\\n\")\n",
    "    print(f\"Top {top_k} propozycji następnego tokenu:\\n\")\n",
    "\n",
    "    for prob, tok_id in zip(top_probs, top_ids):\n",
    "        token_str = tokenizer.decode([tok_id.item()])\n",
    "        print(f\"{token_str!r}   ->   p = {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a9fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefiks:\n",
      "Orzeszek jest malutki\n",
      "\n",
      "Top 15 propozycji następnego tokenu:\n",
      "\n",
      "','   ->   p = 0.5331\n",
      "' i'   ->   p = 0.1895\n",
      "'.'   ->   p = 0.0654\n",
      "' ale'   ->   p = 0.0305\n",
      "' ('   ->   p = 0.0172\n",
      "' -'   ->   p = 0.0128\n",
      "' jak'   ->   p = 0.0122\n",
      "' a'   ->   p = 0.0087\n",
      "' ,'   ->   p = 0.0080\n",
      "' –'   ->   p = 0.0077\n",
      "' więc'   ->   p = 0.0067\n",
      "' w'   ->   p = 0.0052\n",
      "' o'   ->   p = 0.0041\n",
      "' z'   ->   p = 0.0039\n",
      "' na'   ->   p = 0.0034\n"
     ]
    }
   ],
   "source": [
    "show_next_token_suggestions('Orzeszek jest malutki', top_k=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
