{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd8e4a8",
   "metadata": {},
   "source": [
    "# Wykład numer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5af23",
   "metadata": {},
   "source": [
    "Technika Few-Shots\n",
    "\n",
    "Główna idea:\n",
    "- Wybrać kilka demnstracji\n",
    "- Wkleić je do prompta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf9727",
   "metadata": {},
   "source": [
    "Prawdopodobieństwo\n",
    "\n",
    "\"markdown.extension.preview.autoShowPreviewToSide\": true\n",
    "\n",
    "\n",
    "P(w<sub>1</sub> ... w<sub>n</sub>) = P(w<sub>1</sub>)P(w<sub>2</sub> | w<sub>1</sub>) <sub></sub>\n",
    "\n",
    "{\n",
    "    \"siema\": \"Czesc\",\n",
    "    \"surrname\": \"Co tam\",\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "<sub>123</sub>\n",
    "term\n",
    ": siemka\n",
    "\n",
    "- [x] Siemka\n",
    "- []\n",
    "\n",
    ":joy:\n",
    "\n",
    "<sup>2</sup>\n",
    "H~2~0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee529d8",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"color: white\">\n",
    "\n",
    "## Wzór na Soft Max\n",
    "\n",
    "</div>\n",
    "<div style=\"color: white\">\n",
    "\n",
    "\n",
    "<p align=\"center\" style=\"color: white\"> Wektor Logits'ów</p>\n",
    "\n",
    "$$\n",
    "    Z = \\begin{pmatrix} z_1 & z_2 & ... & z_{n-1} & z_n \\end{pmatrix} \n",
    "$$ \n",
    "\n",
    "$$\n",
    "    softmax({z_k}) = \\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "    p_k = \\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1b0da",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"color: white\">\n",
    "\n",
    "## Wzór na Log Soft Max\n",
    "\n",
    "</div>\n",
    "<div style=\"color: white\">\n",
    "\n",
    "$$\n",
    "    logsoftmax({z_k}) = log(\\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}})\n",
    "$$\n",
    "\n",
    "$$ \n",
    "    logsoftmax({z_k}) = log(e^{z_k}) - log(\\sum_{i=1}^n e^{z_i})\n",
    "$$\n",
    "\n",
    "$$\n",
    "    logsoftmax({z_k}) = z_k - log(\\sum_{i=1}^n e^{z_i}) \n",
    "$$\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2eb014",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        Kod z wykładu\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83dc7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[-22.9720, -25.3151, -25.6619,  ..., -14.4614, -18.1689, -13.7099],\n",
      "         [-24.8636, -26.9614, -28.9603,  ..., -17.5621, -16.1743, -12.8644],\n",
      "         [-25.4614, -24.5363, -25.7523,  ..., -21.0725,  -9.4578, -15.4223],\n",
      "         [-27.2302, -31.5633, -30.7097,  ..., -17.6647, -14.6530, -13.6264]]])\n",
      "tensor([[-7.5045, -4.2623, -6.6108, -2.0110]])\n",
      "Ala ma kota. -20.388588\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "model_name = 'flax-community/papuGaPT2'\n",
    "device = 'cuda'\n",
    "device = 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    print(logp)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    print(logp_label)\n",
    "    return logp_label\n",
    "    \n",
    "            \n",
    "def sentence_prob(sentence_txt):\n",
    "    input_ids = tokenizer(sentence_txt, return_tensors='pt')['input_ids'].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids)\n",
    "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], input_ids[:, 1:])\n",
    "        seq_log_probs = torch.sum(log_probs)\n",
    "    return seq_log_probs.cpu().numpy()  \n",
    "    \n",
    "sentences = [\n",
    "  'Ala ma kota.',  \n",
    "]\n",
    "\n",
    "print ()\n",
    "for s in sentences:\n",
    "    print (s, sentence_prob(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d75cd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.1\n",
      "tensor([[0.1444, 0.0322, 0.7907, 0.0088, 0.0239]])\n",
      "log:  tensor([-0.4170, -1.4170, -2.3170])\n",
      "84.34167775823985\n",
      "[np.float64(0.14444215818926234), np.float64(0.03222940188895495), np.float64(0.7906687750755603), np.float64(0.008783536685210685), np.float64(0.0238761281610116)]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import e, pow\n",
    "\n",
    "logits = [2.5, 1.0, 4.2, -0.3, 0.7]\n",
    "print(np.sum([2.5, 1.0, 4.2, -0.3, 0.7]))\n",
    "a = torch.tensor([[2.5, 1.0, 4.2, -0.3, 0.7]])\n",
    "print(torch.softmax(a, dim=1))\n",
    "b = torch.tensor([2.0, 1.0, 0.1])\n",
    "\n",
    "print('log: ', torch.log_softmax(b, dim=0))\n",
    "\n",
    "s = np.sum([pow(e, l) for l in logits])\n",
    "print(s)\n",
    "for i in range(len(logits)):\n",
    "    logits[i] = pow(e, logits[i]) / s\n",
    "\n",
    "print(logits)\n",
    "print(np.sum(logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1adb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ab8e41",
   "metadata": {},
   "source": [
    "<div align=\"center\"> \n",
    "\n",
    "# Beam Search\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335ffb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe31ba03",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Perplexity (miara nieokreśloności)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "Intuicje\n",
    "1. To co się zdaza, powinno mieć wysokie prawdopodobienstwo\n",
    "2. Gdy dobrze perzewidumey koleje slowo ( na podstawie pelnego prefiksu) to jestesmy w stanie dobrze kompresowwac tekst\n",
    "3. Oczywiście powinniśmy dzielic korpus na czesc przeszla zdarzyla sie i przyszla zdarzy sie chemy jej dac spore prawdopodobienstwo, ale jej nie znamy\n",
    "---\n",
    "Wzór\n",
    "\n",
    "$$\n",
    "    PP(w_1 ... w_N) = P(w_1 ... w_N)^{-\\frac{1}{N}}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6dbcc",
   "metadata": {},
   "source": [
    "Mozna rozumieć perplexity jako średni wazony współczynnik rozgałęzienia języka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dac741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
