{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f195f77b",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"\">\n",
    "\n",
    "# Zadanie 3\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b0e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "CHROMOSOME_LEN = 20\n",
    "POPULATION_LEN = 3\n",
    "ITERATION_NUM = 100\n",
    "\n",
    "def binary_random(p):\n",
    "    return 1 if random.random() <= p else 0\n",
    "\n",
    "def random_individual(p: List[float]) -> np.ndarray:\n",
    "    return np.array([binary_random(pi) for pi in p])\n",
    "\n",
    "def random_population(p: List[float], N: int = POPULATION_LEN) -> np.ndarray:\n",
    "    return np.array([random_individual(p) for _ in range(N)])\n",
    "\n",
    "def population_evaluation(P: List[List[int]], F):\n",
    "    return np.array([F(x) for x in P])\n",
    "\n",
    "def population_based_incremental_learning(F, N: int, O1, O2, O3):\n",
    "    pro_vector = np.array([0.5 for _ in range(N)])                      # Initial Probabilty Vector\n",
    "    ran_population = random_population(pro_vector, POPULATION_LEN)      # Initial Random Population \n",
    "    fitness = population_evaluation(ran_population, F)                  # Results\n",
    "    best_individual = []\n",
    "    best_score = 0\n",
    "    for _ in range(ITERATION_NUM):\n",
    "        x = ran_population[np.argmax(fitness)]\n",
    "\n",
    "        if best_score < fitness[np.argmax(fitness)]:\n",
    "            best_score = fitness[np.argmax(fitness)]\n",
    "            best_individual = x\n",
    "\n",
    "        for i in range(N):\n",
    "            pro_vector[i] = pro_vector[i] * (1 - O1) + (x[i] * O1)\n",
    "\n",
    "        for i in range(N):\n",
    "            if random.random() <= O2:\n",
    "                pro_vector[i] = pro_vector[i] * (1 - O3) + O3 * binary_random(0.5)\n",
    "\n",
    "        ran_population = random_population(pro_vector, POPULATION_LEN)\n",
    "        fitness = population_evaluation(ran_population, F)\n",
    "\n",
    "    return best_individual, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301730c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "raws = []\n",
    "expert = []\n",
    "classification = []\n",
    "\n",
    "with open('lista01/ImageRawReduced.txt', \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        raws.append(line.split())\n",
    "\n",
    "with open('lista01/ImageExpertReduced.txt', \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        expert.append(line.split())\n",
    "\n",
    "with open ('lista01/ClassificationRules.txt', \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        classification.append(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba30aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0\n",
      " 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0]: 98.02\n"
     ]
    }
   ],
   "source": [
    "def func(seq: List[int]) -> float:\n",
    "    n = len(seq)\n",
    "    m = len(classification[0])\n",
    "    res = 0\n",
    "\n",
    "    for p in range(m):\n",
    "        c = Counter()\n",
    "\n",
    "        c[classification[seq != 0][p]] += 1\n",
    "\n",
    "        if c.most_common(1)[0][0] == expert[0][p]:\n",
    "            res += 1\n",
    "\n",
    "    return res / m\n",
    "        \n",
    "x, s = population_based_incremental_learning(func, 266, 0.1, 0.1, 0.1)\n",
    "print(f'{x}: {(s * 100):.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745c21f",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62f3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # ---------- SZYBKIE WCZYTANIE DANYCH ----------\n",
    "# def load_data(paths):\n",
    "#     rules_path, expert_path = paths\n",
    "\n",
    "#     # 1) Wczytaj jako float (działa dla \"1.0000000e+000\"), potem zaokrąglij -> int\n",
    "#     expert_f = np.loadtxt(expert_path, dtype=np.float32)       # (9350,) lub (1,9350)\n",
    "#     expert   = np.rint(expert_f).astype(np.int16).ravel()      # 1..3\n",
    "\n",
    "#     rules_f  = np.loadtxt(rules_path, dtype=np.float32)        # (266,9350) lub (9350,266)\n",
    "#     rules    = np.rint(rules_f).astype(np.int16)\n",
    "\n",
    "#     # 2) Orientacja: chcemy (R x M) = (liczba_reguł x liczba_punktów)\n",
    "#     if rules.shape[1] != expert.shape[0] and rules.shape[0] == expert.shape[0]:\n",
    "#         rules = rules.T\n",
    "\n",
    "#     R, M = rules.shape\n",
    "#     assert M == expert.shape[0], f\"Niezgodne wymiary: rules {rules.shape}, expert {expert.shape}\"\n",
    "\n",
    "#     # 3) Bezpieczne sprowadzenie do 0..2\n",
    "#     if not np.all(np.isin(expert, [1,2,3])):\n",
    "#         # jeżeli trafi się np. 0 lub 4 przez błąd zapisu - przytnij i ostrzeż\n",
    "#         expert = np.clip(expert, 1, 3)\n",
    "#     expert0 = (expert - 1).astype(np.uint8)\n",
    "\n",
    "#     rules_ok = rules.copy()\n",
    "#     if not np.all(np.isin(rules_ok, [1,2,3])):\n",
    "#         rules_ok = np.clip(rules_ok, 1, 3)\n",
    "#     rules0 = (rules_ok - 1).astype(np.uint8)  # (R,M) w 0..2\n",
    "\n",
    "#     # 4) Prekomputacja one-hot: OH[r,k,m] = 1 gdy reguła r przewiduje klasę k dla punktu m\n",
    "#     OH = np.zeros((R, 3, M), dtype=np.uint8)\n",
    "#     for k in range(3):\n",
    "#         OH[:, k, :] = (rules0 == k)\n",
    "\n",
    "#     # szybki sanity-check\n",
    "#     # print(\"expert0:\", expert0.shape, \"OH:\", OH.shape)  # (9350,), (266,3,9350)\n",
    "\n",
    "#     return expert0, OH\n",
    "\n",
    "\n",
    "\n",
    "# # ---------- BARDZO SZYBKA EWALUACJA POPULACJI ----------\n",
    "# def fitness_population(pop, OH, expert0):\n",
    "#     \"\"\"\n",
    "#     pop: bool/0-1, shape (P, R) lub (R,)\n",
    "#     OH:  uint8,   shape (R, 3, M)  - prekomputacja one-hot\n",
    "#     expert0: uint8, shape (M,)\n",
    "#     Zwraca: wektor dokładności dla całej populacji (P,) lub skalar gdy wejście było 1D\n",
    "#     \"\"\"\n",
    "#     if pop.ndim == 1:\n",
    "#         pop = pop[None, :]\n",
    "#     P, R = pop.shape\n",
    "#     M = expert0.shape[0]\n",
    "\n",
    "#     # Liczymy głosy: tensordot po wymiarze reguł\n",
    "#     # counts ma wymiar (P, 3, M) - liczba głosów na każdą klasę 0..2 w każdym punkcie\n",
    "#     # Uwaga: rzutujemy na mały typ, żeby było lekko pamięciowo\n",
    "#     counts = np.tensordot(pop.astype(np.int16), OH.astype(np.int16), axes=(1, 0))  # (P, 3, M)\n",
    "\n",
    "#     # Predykcja to argmax po klasie (wiąże remisy na korzyść mniejszego indeksu: 0 > 1 > 2)\n",
    "#     pred = np.argmax(counts, axis=1).astype(np.uint8)  # (P, M)\n",
    "#     acc = (pred == expert0[None, :]).mean(axis=1)      # (P,)\n",
    "\n",
    "#     # Osobnik bez żadnej reguły dostaje 0.0\n",
    "#     empty = (pop.sum(axis=1) == 0)\n",
    "#     if np.any(empty):\n",
    "#         acc[empty] = 0.0\n",
    "\n",
    "#     return acc[0] if acc.shape[0] == 1 else acc\n",
    "\n",
    "\n",
    "# # ---------- SZYBKI PBIL W PEŁNI WEKTORYZOWANY ----------\n",
    "# def pbil_batched(expert0, OH, dim, *,\n",
    "#                  O1=0.1, O2=0.02, O3=0.05,\n",
    "#                  pop_size=32, iters=200, seed=0,\n",
    "#                  early_stop_patience=30):\n",
    "#     \"\"\"\n",
    "#     - pop_size 32..64 działa zwykle dużo lepiej niż 3 i wciąż jest szybkie z batched ewaluacją\n",
    "#     - early stopping zatrzyma się, gdy długo brak poprawy\n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     prob = np.full(dim, 0.5, dtype=np.float32)\n",
    "\n",
    "#     def sample_population(prob, size):\n",
    "#         return (rng.random((size, prob.shape[0])) <= prob).astype(np.uint8)\n",
    "\n",
    "#     pop = sample_population(prob, pop_size)\n",
    "#     fit = fitness_population(pop, OH, expert0)\n",
    "\n",
    "#     best_idx = int(np.argmax(fit))\n",
    "#     best_x = pop[best_idx].copy()\n",
    "#     best_f = float(fit[best_idx])\n",
    "#     no_imp = 0\n",
    "\n",
    "#     for _ in range(iters):\n",
    "#         elite = pop[int(np.argmax(fit))].astype(np.float32)\n",
    "\n",
    "#         # krok uczenia PBIL\n",
    "#         prob = prob * (1.0 - O1) + elite * O1\n",
    "\n",
    "#         # mutacja wektorowa\n",
    "#         mut_mask = rng.random(dim) <= O2\n",
    "#         if mut_mask.any():\n",
    "#             rnd_bits = (rng.random(mut_mask.sum()) <= 0.5).astype(np.float32)\n",
    "#             prob[mut_mask] = prob[mut_mask] * (1.0 - O3) + rnd_bits * O3\n",
    "\n",
    "#         # stabilizacja\n",
    "#         prob = np.clip(prob, 1e-3, 1.0 - 1e-3)\n",
    "\n",
    "#         # nowa populacja i batched fitness\n",
    "#         pop = sample_population(prob, pop_size)\n",
    "#         fit = fitness_population(pop, OH, expert0)\n",
    "\n",
    "#         idx = int(np.argmax(fit))\n",
    "#         if fit[idx] > best_f:\n",
    "#             best_f = float(fit[idx])\n",
    "#             best_x = pop[idx].copy()\n",
    "#             no_imp = 0\n",
    "#         else:\n",
    "#             no_imp += 1\n",
    "\n",
    "#         if no_imp >= early_stop_patience:\n",
    "#             break\n",
    "\n",
    "#     return best_x.astype(np.uint8), best_f\n",
    "\n",
    "\n",
    "# # ---------- PRZYKŁADOWE UŻYCIE ----------\n",
    "# if __name__ == \"__main__\":\n",
    "#     expert0, OH = load_data((\"lista01/ClassificationRules.txt\",\n",
    "#                              \"lista01/ImageExpertReduced.txt\"))\n",
    "#     R = OH.shape[0]  # liczba reguł, powinna wynosić 266\n",
    "\n",
    "#     best_x, best_score = pbil_batched(expert0, OH, dim=R,\n",
    "#                                       O1=0.1, O2=0.02, O3=0.05,\n",
    "#                                       pop_size=48, iters=400, seed=42,\n",
    "#                                       early_stop_patience=60)\n",
    "\n",
    "#     print(\"Najlepsza dokładność:\", best_score)\n",
    "#     # Jeśli chcesz jeszcze raz potwierdzić:\n",
    "#     # print(\"Check:\", fitness_population(best_x, OH, expert0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07d80f",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"color: cyan\">\n",
    "\n",
    "# Zadanie 4\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631a3225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.88373645e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 2.82737920e-02 1.00000000e+00 1.00000000e+00 1.97502068e-01\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 8.64374042e-01 9.15355822e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.17022802e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.72946099e-01 3.43928018e-01\n",
      " 4.08793583e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.87585931e-01 0.00000000e+00 9.32201852e-01 6.61708339e-01\n",
      " 0.00000000e+00 2.86950140e-01 7.26113700e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 7.66333374e-01 4.01792975e-02 1.00000000e+00\n",
      " 5.84193324e-02 0.00000000e+00 0.00000000e+00 1.00549916e-02\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.85733954e-01 1.00000000e+00\n",
      " 0.00000000e+00 3.07220970e-02 0.00000000e+00 0.00000000e+00\n",
      " 9.98019742e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 9.94632435e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.52192163e-01\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 1.00846640e-01\n",
      " 9.68659574e-01 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 3.88423952e-01 1.00000000e+00 0.00000000e+00 9.60848586e-01\n",
      " 7.59476603e-01 1.00000000e+00 0.00000000e+00 9.89231086e-01\n",
      " 1.00000000e+00 8.41791686e-01 1.00000000e+00 7.82887744e-04\n",
      " 0.00000000e+00 7.52376660e-03 1.00000000e+00 9.31871821e-02\n",
      " 9.86153167e-01 1.00000000e+00 1.00000000e+00 3.00448024e-02\n",
      " 1.00000000e+00 9.28397230e-01 0.00000000e+00 1.00000000e+00\n",
      " 3.05396804e-01 1.00000000e+00 1.18683498e-02 0.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 7.59198336e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.10676112e-01 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 3.25981833e-01 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.40637432e-02 0.00000000e+00\n",
      " 9.90728205e-01 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 9.58284140e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.16744248e-01 0.00000000e+00 0.00000000e+00 4.01400173e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 9.79218374e-01\n",
      " 1.00000000e+00 0.00000000e+00 7.01859327e-01 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 7.50693304e-02 0.00000000e+00\n",
      " 9.28204539e-01 9.45823923e-01 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.88445783e-01 1.00000000e+00 8.90886671e-03\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 2.41195571e-02\n",
      " 8.42697112e-01 1.00000000e+00 1.00000000e+00 8.92569222e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.27223114e-01 8.15479151e-02 0.00000000e+00\n",
      " 9.28822892e-02 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.44685509e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+00 9.82828236e-02\n",
      " 0.00000000e+00 1.00000000e+00 8.12983512e-02 2.66575527e-01\n",
      " 1.00000000e+00 7.60365326e-01]: 89.19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "CHROMOSOME_LEN = 20\n",
    "POPULATION_LEN = 3\n",
    "ITERATION_NUM = 100\n",
    "\n",
    "def binary_random(p):\n",
    "    return 1 if random.random() <= p else 0\n",
    "\n",
    "def weight_random():\n",
    "    return random.random()\n",
    "\n",
    "def change_weight(x, p):\n",
    "    if random.random() <= p:\n",
    "       return max(min(x + (0.1 * random.random()), 1.0), 0.0)\n",
    "    else: \n",
    "        return max(min(x - (0.1 * random.random()), 1.0), 0.0)\n",
    "\n",
    "def random_individual(p: List[float]) -> np.ndarray:\n",
    "    return np.array([weight_random() for _ in p])\n",
    "\n",
    "def new_individual(individual, p: List[float]) -> np.ndarray:\n",
    "    return np.array([change_weight(individual[i], pi) for i, pi in enumerate(p)])\n",
    "\n",
    "def random_population(p: List[float], N: int = POPULATION_LEN) -> np.ndarray:\n",
    "    return np.array([random_individual(p) for _ in range(N)])\n",
    "\n",
    "def new_population(population, p: List[float], N: int = POPULATION_LEN) -> np.ndarray:\n",
    "    return np.array([new_individual(population[i], p) for i in range(N)])\n",
    "\n",
    "def population_evaluation(P: List[List[float]], F):\n",
    "    return np.array([F(x) for x in P])\n",
    "\n",
    "def population_based_incremental_learning(F, N: int, O1, O2, O3):\n",
    "    pro_vector = np.array([0.5 for _ in range(N)])                      # Initial Probabilty Vector\n",
    "    ran_population = random_population(pro_vector, POPULATION_LEN)      # Initial Random Population \n",
    "    fitness = population_evaluation(ran_population, F)                  # Results\n",
    "    best_individual = []\n",
    "    best_score = 0\n",
    "    for _ in range(ITERATION_NUM):\n",
    "        x = ran_population[np.argmax(fitness)]\n",
    "\n",
    "        if best_score < fitness[np.argmax(fitness)]:\n",
    "            best_score = fitness[np.argmax(fitness)]\n",
    "            best_individual = x\n",
    "\n",
    "        for i in range(N):\n",
    "            pro_vector[i] = pro_vector[i] * (1 - O1) + (x[i] * O1)\n",
    "\n",
    "        for i in range(N):\n",
    "            if random.random() <= O2:\n",
    "                pro_vector[i] = pro_vector[i] * (1 - O3) + O3 * binary_random(0.5)\n",
    "\n",
    "        ran_population = new_population(ran_population, pro_vector, POPULATION_LEN)\n",
    "        fitness = population_evaluation(ran_population, F)\n",
    "\n",
    "    return best_individual, best_score\n",
    "\n",
    "def func(seq: List[float]) -> float:\n",
    "    n = len(seq)\n",
    "    m = len(classification[0])\n",
    "    res = 0\n",
    "\n",
    "    for p in range(m):\n",
    "        c = Counter()\n",
    "        for i in range(n):\n",
    "            if seq[i] == 0:\n",
    "                continue\n",
    "            c[classification[i][p]] += seq[i]\n",
    "\n",
    "        if c.most_common(1)[0][0] == expert[0][p]:\n",
    "            res += 1\n",
    "\n",
    "    return res / m\n",
    "\n",
    "\n",
    "x, s = population_based_incremental_learning(func, 266, 0.1, 0.1, 0.1)\n",
    "print(f'{x}: {(s * 100):.02f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
